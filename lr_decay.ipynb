{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\Milosz\\AppData\\Local\\Temp\\ipykernel_45152\\625103501.py:17: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    max_iters: int = 10\n",
    "    learning_rate: float = 10\n",
    "    min_lr: float = 2\n",
    "    min_lr_decay_ratio: float = 0.1\n",
    "    min_lr_iter_ratio: float = 0.1\n",
    "    warmup_iter_ratio: float = 0.1\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_dataset, val_dataset=None, config=TrainConfig):\n",
    "        self.config = config\n",
    "    def get_lr(self, cur_iter):\n",
    "        \"\"\"\n",
    "        LR ^\n",
    "        |\n",
    "        |      /‾‾\\          learning_rate\n",
    "        |     /    ‾‾\\\n",
    "        |    /        ‾\\\n",
    "        |   /           ‾\\\n",
    "        |  /              \\  min_lr_decayed\n",
    "        | /\n",
    "        min_lr\n",
    "        +------+----------+--> iter\n",
    "        0     warmup_    max_\n",
    "            end_iter   iters\n",
    "        \"\"\"\n",
    "        #first  LR warmup  from min_lr to learning_rate at (warmup_iter_ratio % of iters)\n",
    "        config = self.config\n",
    "        warmup_end_iter = config.warmup_iter_ratio * config.max_iters\n",
    "        if cur_iter < warmup_end_iter:\n",
    "            return config.min_lr \\\n",
    "                + (config.learning_rate-config.min_lr) \\\n",
    "                * (cur_iter/warmup_end_iter)\n",
    "        # cosine LR decay from learning_rate at (warmup_iter_ratio % of iters) down to min_lr_ratio at (min_lr_iter_ratio % of iters)\n",
    "        min_lr_decayed = config.min_lr_decay_ratio * config.learning_rate\n",
    "        if cur_iter < config.max_iters:\n",
    "            return min_lr_decayed \\\n",
    "                    + math.cos((cur_iter - warmup_end_iter) / (config.max_iters - warmup_end_iter) * math.pi/2) \\\n",
    "                    * (config.learning_rate - min_lr_decayed)\n",
    "        return min_lr_decayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0,\n",
       " 10.0,\n",
       " 9.863269777109872,\n",
       " 9.457233587073176,\n",
       " 8.794228634059948,\n",
       " 7.894399988070802,\n",
       " 6.785088487178855,\n",
       " 5.500000000000001,\n",
       " 4.0781812899310195,\n",
       " 2.562833599002374]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(None,None,)\n",
    "[trainer.get_lr(iter) for iter in range(TrainConfig.max_iters)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
